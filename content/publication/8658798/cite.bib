@inproceedings{8658798,
 abstract = {Autonomous driving requires operation in different behavioral modes ranging from lane following and intersection crossing to turning and stopping. However, most existing deep learning approaches to autonomous driving do not consider the behavioral mode in the training strategy. This paper describes a technique for learning multiple distinct behavioral modes in a single deep neural network through the use of multi-modal multi-task learning. We study the effectiveness of this approach, denoted MultiNet, using self-driving model cars for driving in unstructured environments such as sidewalks and unpaved roads. Using labeled data from over one hundred hours of driving our fleet of 1/10th scale model cars, we trained different neural networks to predict the steering angle and driving speed of the vehicle in different behavioral modes. We show that in each case, MultiNet networks outperform networks trained on individual modes while using a fraction of the total number of parameters.},
 author = {S. Chowdhuri and T. Pankaj and K. Zipser},
 booktitle = {2019 IEEE Winter Conference on Applications of Computer Vision (WACV)},
 doi = {10.1109/WACV.2019.00164},
 issn = {1550-5790},
 keywords = {automobiles;learning (artificial intelligence);neural nets;remotely operated vehicles;road safety;roads;traffic engineering computing;multimodal multitask learning;autonomous driving;behavioral mode;multiple distinct behavioral modes;self-driving model cars;steering angle;driving speed;MultiNet networks;individual modes;deep learning;single deep neural networks;scale model cars;Automobiles;Task analysis;Training;Autonomous vehicles;Roads;Trajectory;Kernel},
 month = {Jan},
 number = {},
 pages = {1496-1504},
 title = {MultiNet: Multi-Modal Multi-Task Learning for Autonomous Driving},
 volume = {},
 year = {2019}
}

